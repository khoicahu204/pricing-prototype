{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9ebc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç So s√°nh m√¥ h√¨nh d·ª± ƒëo√°n gi√° cho Toyota XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
      "             n_jobs=None, num_parallel_tree=None, ...)\n",
      "               Model         MAE  R¬≤ Score\n",
      "0  Linear Regression  26070676.0     0.281\n",
      "1      Random Forest   4747137.0     0.943\n",
      "2            XGBoost  12102383.0     0.865\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Load d·ªØ li·ªáu\n",
    "df = pd.read_csv(\"cleaned_data_sorted.csv\")\n",
    "\n",
    "# 2. L·ªçc m·ªôt d√≤ng xe ƒë·ªÉ test (v√≠ d·ª•: Toyota Vios)\n",
    "brand = \"Toyota\"\n",
    "model = \"zace\"\n",
    "\n",
    "df_filtered = df[\n",
    "    (df[\"brand\"].str.lower() == brand.lower()) &\n",
    "    (df[\"model\"].str.lower() == model.lower())\n",
    "].dropna(subset=[\"manufacture_date\", \"mileage_v2\", \"price\"])\n",
    "\n",
    "# 3. T·∫°o bi·∫øn X v√† y\n",
    "X = df_filtered[[\"manufacture_date\", \"mileage_v2\"]]\n",
    "y = df_filtered[\"price\"]\n",
    "\n",
    "# 4. Chia train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": round(mae, 0),\n",
    "        \"R¬≤ Score\": round(r2, 3)\n",
    "    })\n",
    "\n",
    "# 6. Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"üîç So s√°nh m√¥ h√¨nh d·ª± ƒëo√°n gi√° cho\", brand, model)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
